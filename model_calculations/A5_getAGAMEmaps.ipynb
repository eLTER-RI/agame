{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGAME Workflow. Get AGAME maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deims\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import ee\n",
    "import xarray\n",
    "import geemap\n",
    "import rioxarray\n",
    "from pyproj import CRS\n",
    "from xgboost import XGBRegressor\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import mapping\n",
    "from shapely.geometry import Polygon, box\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_unique_years(date_range_values):\n",
    "    unique_years = set()\n",
    "    for date in date_range_values:\n",
    "        year = date.split('-')[0] \n",
    "        unique_years.add(year)    \n",
    "\n",
    "    unique_years = sorted(unique_years)\n",
    "\n",
    "    return unique_years\n",
    "\n",
    "def get_coordinates_area(df, site):\n",
    "    site_url = df['deims'].loc[df['sites_ids'] == site].values[0]\n",
    "    latitude  = df['lat'].loc[df['sites_ids'] == site].values[0]\n",
    "    longitude = df['lon'].loc[df['sites_ids'] == site].values[0]\n",
    "    if pd.isna(site_url):\n",
    "        raise ValueError(\"The site DEIMS url is empty. Please provide a valid site URL.\")\n",
    "    else:\n",
    "        boundaries   = deims.getSiteBoundaries([site_url])\n",
    "        information = deims.getSiteById(site_id=site_url)\n",
    "    return boundaries, latitude, longitude, information\n",
    "\n",
    "def map_coordinates_area(df, boundaries, site):\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=gpd.points_from_xy(df.lon, df.lat),\n",
    "        crs=\"EPSG:3857\"\n",
    "    )\n",
    "    gdf = gdf.loc[gdf['sites_ids'] == site]\n",
    "    centroid = gdf.geometry.centroid.union_all()\n",
    "    m = folium.Map(location=[centroid.y, centroid.x], zoom_start=12)\n",
    "    for idx, row in gdf.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            popup=row['sites_ids']\n",
    "        ).add_to(m)\n",
    "\n",
    "    folium.GeoJson(boundaries).add_to(m)\n",
    "\n",
    "    return m, gdf\n",
    "\n",
    "def get_gee_area(boundaries):\n",
    "    total_bounds = boundaries.total_bounds\n",
    "    aoi = ee.Geometry.Rectangle([total_bounds[0], total_bounds[1], total_bounds[2], total_bounds[3]])\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, 'Bounding Box')\n",
    "\n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 10)\n",
    "\n",
    "    return Map, aoi\n",
    "\n",
    "def get_gee_area_from_gpp(polygon_gdf):\n",
    "    # Ensure the GeoDataFrame contains a valid geometry column\n",
    "    if polygon_gdf.empty or polygon_gdf.geom_type.iloc[0] != 'Polygon':\n",
    "        raise ValueError(\"GeoDataFrame is empty or does not contain Polygon geometries.\")\n",
    "    \n",
    "    # Get the first polygon from the GeoDataFrame\n",
    "    polygon = polygon_gdf.geometry.iloc[0]\n",
    "\n",
    "    # Convert the Shapely Polygon to GeoJSON-like dict\n",
    "    geojson = mapping(polygon)\n",
    "    \n",
    "    # Create an Earth Engine Geometry from the GeoJSON\n",
    "    aoi = ee.Geometry.Polygon(geojson['coordinates'])\n",
    "\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, 'Bounding Box')\n",
    "\n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 15)\n",
    "    \n",
    "    return Map, aoi\n",
    "\n",
    "def get_gee_area_from_gpp_multipolygon(geodf):\n",
    "    \n",
    "    if geodf.empty:\n",
    "        raise ValueError(\"GeoDataFrame is empty.\")\n",
    "    \n",
    "    # Get the first geometry from the GeoDataFrame\n",
    "    geom = geodf.geometry.iloc[0]\n",
    "\n",
    "    # Check the geometry type\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geojson = mapping(geom)\n",
    "        aoi = ee.Geometry.Polygon(geojson['coordinates'])\n",
    "    elif geom.geom_type == 'MultiPolygon':\n",
    "        # Convert each Polygon in the MultiPolygon to GeoJSON and create ee.Geometry.MultiPolygon\n",
    "        geojson = mapping(geom)\n",
    "        polygons = [ee.Geometry.Polygon(polygon) for polygon in geojson['coordinates']]\n",
    "        aoi = ee.Geometry.MultiPolygon(polygons)\n",
    "        # aoi = ee.Geometry.Polygon(polygons[0])\n",
    "    else:\n",
    "        raise ValueError(\"GeoDataFrame contains unsupported geometry type. Only Polygon and MultiPolygon are supported.\")\n",
    "\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, 'Bounding Box')\n",
    "\n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 15)\n",
    "    \n",
    "    return Map, aoi\n",
    "\n",
    "def get_gee_area_from_gpp_multipolygon_single_polygon(geodf, gdf, num_polygon):\n",
    "        \n",
    "    # Get the first geometry from the GeoDataFrame\n",
    "    if not geodf.empty:    \n",
    "        geom = geodf.geometry.iloc[0]\n",
    "    else:\n",
    "        geom = gdf.geometry.iloc[0]\n",
    "\n",
    "    # Check the geometry type\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geojson = mapping(geom)\n",
    "        aoi = ee.Geometry.Polygon(geojson['coordinates'])\n",
    "    elif geom.geom_type == 'MultiPolygon':\n",
    "        # Convert each Polygon in the MultiPolygon to GeoJSON and create ee.Geometry.MultiPolygon\n",
    "        geojson = mapping(geom)\n",
    "        first_polygon_coords = geojson['coordinates'][num_polygon]\n",
    "        polygon = Polygon(first_polygon_coords[0]) \n",
    "        geojson_polygon = polygon.__geo_interface__\n",
    "        aoi = ee.Geometry.Polygon(geojson_polygon['coordinates'])\n",
    "    elif geom.geom_type == 'Point':\n",
    "        print(f\"The deims site does not have ecosystem boundaries. An area of 1 square kilometer will be created with centroid in the ecosystem's longitude and latitude\")\n",
    "        longitude = geom.x\n",
    "        latitude = geom.y\n",
    "        gee_point = ee.Geometry.Point([longitude, latitude])\n",
    "        buffer = gee_point.buffer(500) \n",
    "        aoi = buffer.bounds()\n",
    "    else:\n",
    "        raise ValueError(\"GeoDataFrame contains unsupported geometry type. Only Polygon and MultiPolygon are supported.\")\n",
    "    \n",
    "    error_margin = 1  # meter\n",
    "    area_m2 = aoi.area(maxError=error_margin).getInfo()\n",
    "    area_km2 = area_m2 / 1e6\n",
    "    print(f\"The area of the site is {area_m2} square meters\")\n",
    "    print(f\"The area of the site is {area_km2} square kilometers\\n\")\n",
    "\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, \"Site's area\")\n",
    "\n",
    "    if geom.geom_type != 'Point' and area_km2 < 1:\n",
    "        print(f\"The area of the site is below 1 square kilometer. A new area with a minimun of 1 square kilometer will be created\")\n",
    "        centroid = aoi.centroid()\n",
    "        buffer = centroid.buffer(500)\n",
    "        aoi = buffer.bounds()\n",
    "        error_margin = 1  # meter\n",
    "        area_m2 = aoi.area(maxError=error_margin).getInfo()\n",
    "        area_km2 = area_m2 / 1e6\n",
    "        print(f\"The new area of the site is {area_m2} square meters\")\n",
    "        print(f\"The mew area of the site is {area_km2} square kilometers\")\n",
    "        Map.addLayer(aoi, {}, \"New site's area\")\n",
    "\n",
    "    if geom.geom_type != 'Point' and area_km2 > 25:\n",
    "        print(f\"The area of the site is higher than 25 square kilometer. A new area with a maximun of 25 square kilometer will be created\")\n",
    "        centroid = aoi.centroid()\n",
    "        buffer = centroid.buffer(2500)\n",
    "        aoi = buffer.bounds()\n",
    "        error_margin = 1  # meter\n",
    "        area_m2 = aoi.area(maxError=error_margin).getInfo()\n",
    "        area_km2 = area_m2 / 1e6\n",
    "        print(f\"The new area of the site is {area_m2} square meters\")\n",
    "        print(f\"The mew area of the site is {area_km2} square kilometers\")\n",
    "        Map.addLayer(aoi, {}, \"New site's area\")\n",
    "        \n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 15)\n",
    "\n",
    "    print(f\"The site geometry is ready to extract Earth Observation data\\n\")\n",
    "    \n",
    "    return Map, aoi\n",
    "\n",
    "def apply_scale_factors_s2(image):\n",
    "    optical_bands = image.select(['B.']).divide(10000)\n",
    "    thermal_bands = image.select(['B.*']).divide(10000)\n",
    "    return image.addBands(optical_bands, None, True).addBands(thermal_bands, None, True)\n",
    "\n",
    "def apply_scale_factors_e5(image):\n",
    "    image = image.divide(24*60*60)\n",
    "    return image\n",
    "\n",
    "# function to derive VIs\n",
    "def calculateVI(image):\n",
    "    '''This method calculates different vegetation indices in a image collection and adds their values as new bands'''\n",
    "\n",
    "    # defining dictionary of bands Sentinel-2 \n",
    "    dict_bands = {\n",
    "\n",
    "        \"blue\"  :  'B2',                              #Blue band                        \n",
    "        \"green\" :  'B3',                              #Green band\n",
    "        \"red\"   :  'B4',                              #Red band\n",
    "        \"red1\"  :  'B5',                              #Red-edge spectral band   \n",
    "        \"red2\"  :  'B6',                              #Red-edge spectral band\n",
    "        \"red3\"  :  'B7',                              #Red-edge spectral band    \n",
    "        \"NIR\"   :  'B8',                              #Near-infrared band\n",
    "        \"NIRn\"  :  'B8A',                             #Near-infrared narrow\n",
    "        \"WV\"    :  'B9',                              #Water vapour\n",
    "        \"SWIR1\" :  'B11',                             #Short wave infrared 1\n",
    "        \"SWIR2\" :  'B12',                             #Short wave infrared 2\n",
    "    }\n",
    "\n",
    "    # specify bands \n",
    "    dict  = dict_bands\n",
    "    blue  = dict[\"blue\"]                              #Blue band                        \n",
    "    green = dict[\"green\"]                             #Green band\n",
    "    red   = dict[\"red\"]                               #Red band\n",
    "    red1  = dict[\"red1\"]                              #Red-edge spectral band    \n",
    "    red2  = dict[\"red2\"]                              #Red-edge spectral band\n",
    "    red3  = dict[\"red3\"]                              #Red-edge spectral band\n",
    "    NIR   = dict[\"NIR\"]                               #Near-infrared band\n",
    "    NIRn  = dict[\"NIRn\"]                              #Near-infrared band\n",
    "    WV    = dict[\"WV\"]                                #Water vapour\n",
    "    SWIR1 = dict[\"SWIR1\"]                             #Short wave infrared 1\n",
    "    SWIR2 = dict[\"SWIR2\"]                             #Short wave infrared 2\n",
    "\n",
    "    bands_for_expressions = {\n",
    "\n",
    "        'blue'  : image.select(blue).divide(10000),\n",
    "        'green' : image.select(green).divide(10000), \n",
    "        'red'   : image.select(red).divide(10000),\n",
    "        'red1'  : image.select(red1).divide(10000), \n",
    "        'red2'  : image.select(red2).divide(10000),\n",
    "        'red3'  : image.select(red3).divide(10000), \n",
    "        'NIR'   : image.select(NIR).divide(10000),\n",
    "        'NIRn'  : image.select(NIRn).divide(10000),\n",
    "        'WV'    : image.select(WV).divide(10000),\n",
    "        'SWIR1' : image.select(SWIR1).divide(10000),\n",
    "        'SWIR2' : image.select(SWIR2).divide(10000)}\n",
    "\n",
    "    # greeness related indices\n",
    "    # NDVI                                                                             (Rouse et al., 1974)\n",
    "    NDVI  = image.normalizedDifference([NIR, red]).rename(\"NDVI\") \n",
    "    # EVI                                                                             \n",
    "    EVI   = image.expression('2.5*(( NIR - red ) / ( NIR + 6 * red - 7.5 * blue + 1 ))', \n",
    "            bands_for_expressions).rename(\"EVI\")\n",
    "    # EVI2                                                                             (Jiang et al., 2008)\n",
    "    EVI2  = image.expression('2.5*(( NIR - red ) / ( NIR + 2.4 * red + 1 ))', \n",
    "            bands_for_expressions).rename(\"EVI2\")\n",
    "\n",
    "    # greeness related indices with Sentinel-2 narrow bands / Red-edge\n",
    "    # Clr\n",
    "    CLr  = image.expression('(red3/red1)-1', bands_for_expressions).rename(\"CLr\")\n",
    "    # Clg\n",
    "    Clg  = image.expression('(red3/green)-1', bands_for_expressions).rename(\"CLg\")\n",
    "    # MTCI\n",
    "    MTCI = image.expression('(red2-red1)/(red1-red)', bands_for_expressions).rename(\"MTCI\")\n",
    "    # MNDVI                                                                            (Add reference)\n",
    "    MNDVI = image.normalizedDifference([red3, red1]).rename(\"MNDVI\")    \n",
    "\n",
    "    # water related indices\n",
    "    # MNDWI                                                                            (Add reference)\n",
    "    MNDWI = image.normalizedDifference([green, SWIR1]).rename(\"MNDWI\")    \n",
    "    # NDWI OR LSWI or NDII or NDMI                                                     (Add reference)\n",
    "    LSWI  = image.normalizedDifference([NIR, SWIR1]).rename(\"LSWI\")\n",
    "    # NDII                                                                             (Hunt & Qu, 2013)\n",
    "    NDII   = image.normalizedDifference([NIR, SWIR2]).rename(\"NDII\")\n",
    "\n",
    "    image = image.addBands(NDVI).addBands(EVI).addBands(EVI2)\n",
    "    image = image.addBands(CLr).addBands(Clg).addBands(MTCI).addBands(MNDVI)\n",
    "    image = image.addBands(MNDWI).addBands(LSWI).addBands(NDII)\n",
    "\n",
    "    return image \n",
    "\n",
    "def maskS2nonvegetation(image):\n",
    "\n",
    "        qa    = image.select('QA60')\n",
    "        scl   = image.select('SCL')\n",
    "        ndvi  = image.select('NDVI')\n",
    "        mndvi = image.select('MNDVI')\n",
    "\n",
    "        cloudBitMask = 1 << 10\n",
    "        cirrusBitMask = 1 << 11\n",
    "\n",
    "        #vegetationMask1 = 4 # vegetation\n",
    "        #vegetationMask2 = 5 # non-vegetated\n",
    "        #vegetationMask3 = 6 # water\n",
    "        #vegetationMask4 = 7 # unclassified\n",
    "        #vegetationMask5 = 11 # snow\n",
    "\n",
    "        ndviMask = -100\n",
    "        mndviMask = -100\n",
    "\n",
    "        # This mask selects vegetation + non-vegetated + water + unclassified + areas with VIs (NDVI and MNDVI) greater that a threshold set in the configuration file\n",
    "        # mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(7)).Or(scl.eq(11)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0)).And(ndvi.gte(ndviMask)).And(mndvi.gte(mndviMask))\n",
    "        mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(7)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0)).And(ndvi.gte(ndviMask)).And(mndvi.gte(mndviMask))\n",
    "        mask = scl.eq(4)\n",
    "        \n",
    "        vegetation = image.updateMask(mask)\n",
    "        return vegetation\n",
    "\n",
    "def get_s2_array(period,aoi,sentinel_bands, number_img, MGRS_TILE=None,cloud_percentage=100,resolution=100):\n",
    "    ic = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterDate(period[0],period[1])\n",
    "    # ic = ic.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',cloud_percentage))\n",
    "    ic = ic.filterBounds(aoi) \n",
    "    if not MGRS_TILE   is None:\n",
    "        print(f'Retriving collection for {MGRS_TILE} tile')\n",
    "        ic = ic.filter(ee.Filter.eq('MGRS_TILE', MGRS_TILE)) \n",
    "    ic = ic.map(apply_scale_factors_s2)\n",
    "    ic = ic.map(calculateVI)\n",
    "    ic = ic.map(maskS2nonvegetation)\n",
    "    ic = ic.select(sentinel_bands)\n",
    "\n",
    "    count = ic.size().getInfo()\n",
    "    print('Number of images:', count)\n",
    "    image_names = ic.aggregate_array('system:id').getInfo()\n",
    "    print('Image names:', image_names)\n",
    "\n",
    "    if count == 0:\n",
    "        print(\"No images found in the period.\")\n",
    "\n",
    "    if count > 1:\n",
    "        print(\"More than one image in the period.\")\n",
    "        \n",
    "        print('Selecting the first image in the collection:', image_names[number_img])\n",
    "\n",
    "        ic = ic.filter(ee.Filter.eq('system:id', image_names[number_img]))\n",
    "        count = ic.size().getInfo()\n",
    "        print('Number of images:', count)\n",
    "        image_names = ic.aggregate_array('system:id').getInfo()\n",
    "        print('Image names:', image_names)\n",
    "\n",
    "    # ic = ee.ImageCollection(ic.mean())\n",
    "    ic_sample = ic.getRegion(aoi, resolution).getInfo()\n",
    "    return ic_sample, ic\n",
    "\n",
    "def get_s2_df(s2_array):\n",
    "    df = pd.DataFrame(s2_array[1:], columns=s2_array[0])\n",
    "    df = df.iloc[:,1:]\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='ms').dt.date\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_e5_array(period,aoi,e5_bands,resolution=100):\n",
    "    e5 = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR').filterDate(period[0],period[1])\n",
    "    e5 = e5.filterBounds(aoi).select(e5_bands)\n",
    "    e5 = e5.map(apply_scale_factors_e5)\n",
    "    e5_sample = e5.getRegion(aoi, resolution).getInfo()\n",
    "    return e5_sample, e5\n",
    "\n",
    "def get_e5_df(e5_array):\n",
    "    dfe5 = pd.DataFrame(e5_array[1:], columns=e5_array[0])\n",
    "    dfe5['time'] = pd.to_datetime(dfe5['id'], format='%Y%m%d')\n",
    "    dfe5 = dfe5.iloc[:,1:]\n",
    "    dfe5.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    dfe5.rename(columns={'surface_net_solar_radiation_sum':'SW_IN_ERA_GEE'}, inplace=True)\n",
    "    return dfe5\n",
    "\n",
    "def merge_s2_e5(s2_df, e5_df):\n",
    "    df1 = s2_df.reset_index()\n",
    "    df2 = e5_df.reset_index()\n",
    "    df_merged = df1.merge(df2, on=['time', 'lat', 'longitude'], how='left')\n",
    "\n",
    "    df_merged = df_merged.dropna()\n",
    "    df_merged.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    return df_merged\n",
    "\n",
    "def map_image(ic, aoi, band, label):\n",
    "    # Define visualization parameters\n",
    "    vis_params = {\n",
    "        'min': 0.5,\n",
    "        'max': 1.0,\n",
    "        'palette': ['red', 'white', 'green']\n",
    "    }\n",
    "\n",
    "    # Create a map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Center the map on the area of interest\n",
    "    Map.centerObject(aoi, 12)\n",
    "\n",
    "    # Add the mean NDVI layer to the map\n",
    "    Map.addLayer(ic.select(band), vis_params, label)\n",
    "\n",
    "    # Display the map\n",
    "    return Map\n",
    "\n",
    "def get_environmental_data(directory_data, filename,sentinel_vi,sentinel_bands, general):\n",
    "    env_df = pd.read_csv(os.path.join(directory_data, filename), index_col='TIMESTAMP', parse_dates=['TIMESTAMP'])\n",
    "\n",
    "    s2_all = env_df.columns.values.tolist()\n",
    "    s2_all = sorted([item for item in s2_all if not (item.endswith('_residual') or \n",
    "                                                    item.endswith('_trend') or \n",
    "                                                    item.endswith('_season'))])\n",
    "\n",
    "    s2_all = sorted([item for item in s2_all if not (item.startswith('CO2') or \n",
    "                                                    item.startswith('H_') or \n",
    "                                                    item.startswith('LE_'))])\n",
    "\n",
    "    s2_all = [item for item in s2_all if item not in sentinel_vi]\n",
    "    s2_all = [item for item in s2_all if item not in sentinel_bands]\n",
    "    #s2_all = [item for item in s2_all if item not in general]\n",
    "\n",
    "    selected_columns = s2_all \n",
    "    env_df = env_df[selected_columns]\n",
    "\n",
    "    return env_df\n",
    "\n",
    "def merge_s2_env_data(s2_df, env_df, expected_columns):\n",
    "    s2_df = s2_df.reset_index()\n",
    "    env_df = env_df.reset_index()\n",
    "    env_df = env_df.rename(columns={'TIMESTAMP':'time'})\n",
    "\n",
    "    df_merged = s2_df.merge(env_df, on=['time'], how='left')\n",
    "    df_merged.set_index(['time','latitude','longitude'], inplace=True)\n",
    "\n",
    "    df_merged = df_merged[expected_columns]\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def predict_gpp(df_merged, model_file):\n",
    "    print('Predicting Gross Primary Production')\n",
    "    loaded_model = XGBRegressor()\n",
    "    loaded_model.load_model(model_file)\n",
    "    y_pred = loaded_model.predict(df_merged)\n",
    "    df_merged['GPP'] = y_pred\n",
    "    ds_gpp = df_merged.to_xarray()\n",
    "    return ds_gpp\n",
    "\n",
    "def plot_save_var(ds, var, netcdf_output, geotif_output):\n",
    "    ds[var].isel(time=0).plot()\n",
    "    crs = CRS.from_epsg(4326) #3857\n",
    "\n",
    "    ds.attrs['crs'] = crs.to_string()\n",
    "    ds[var].to_netcdf(netcdf_output)\n",
    "\n",
    "    da = ds[var].isel(time=0)\n",
    "    da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "    da.rio.to_raster(geotif_output)\n",
    "\n",
    "def sites_info(site_list, directory_data):\n",
    "    df_sites = pd.read_excel(site_list)\n",
    "    df_sites = df_sites.dropna(subset=['deims'])\n",
    "    site_name_list = sorted(df_sites['sites_ids'].values.tolist())\n",
    "    files_list = os.listdir(directory_data)\n",
    "    files_list = sorted([file for file in files_list if any(file.startswith(site_name) for site_name in site_name_list)])\n",
    "\n",
    "    return site_name_list, files_list, df_sites\n",
    "\n",
    "def sites_info_csv(site_list, directory_data):\n",
    "    df_sites = pd.read_csv(site_list, sep=';')\n",
    "    df_sites = df_sites.dropna(subset=['deims'])\n",
    "    site_name_list = sorted(df_sites['sites_ids'].values.tolist())\n",
    "    files_list = os.listdir(directory_data)\n",
    "    files_list = sorted([file for file in files_list if any(file.startswith(site_name) for site_name in site_name_list)])\n",
    "\n",
    "    return site_name_list, files_list, df_sites\n",
    "\n",
    "def plot_save_gpp(ds, site, period, directory_maps): \n",
    "    directory_maps = os.path.join(directory_maps, site)\n",
    "    os.makedirs(directory_maps, exist_ok=True)\n",
    "\n",
    "    print('Saving Gross Primary Production products\\n')   \n",
    "    crs = CRS.from_epsg(4326)\n",
    "    ds.attrs['crs'] = crs.to_string()\n",
    "\n",
    "    #ds['GPP'].to_netcdf(os.path.join(directory_maps, f'{site} - Gross Primary Production ({period[0]}.nc'))\n",
    "    ds['GPP'].to_netcdf(os.path.join(directory_maps, f'{site.lower()}_gpp_{period[0].replace(\"-\", \"\")}.nc'))\n",
    "\n",
    "    da = ds['GPP'].isel(time=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    da.plot()\n",
    "    plt.title(f'{site} - Gross Primary Production (GPP) - {period[0]}')\n",
    "    plt.savefig(os.path.join(directory_maps, f'{site.lower()}_gpp_{period[0].replace(\"-\", \"\")}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "\n",
    "    da.rio.to_raster(\n",
    "        os.path.join(directory_maps, f'{site.lower()}_gpp_{period[0].replace(\"-\", \"\")}.tif'),\n",
    "        driver='COG',\n",
    "        compress='deflate',\n",
    "        nodata=da.attrs.get('_FillValue', None),\n",
    "        dtype=da.dtype.name\n",
    "    )\n",
    "\n",
    "def get_collection_without_clouds(\n",
    "        collection,\n",
    "        year_list,\n",
    "        aoi, \n",
    "        longitude,\n",
    "        latitude,\n",
    "        max_cloud_coverage,\n",
    "        local_cloud_coverage,\n",
    "):\n",
    "    \n",
    "    # function to load data set with specified period and location\n",
    "    def load_catalog(catalog, time, location, bands):\n",
    "        dataset = ee.ImageCollection(catalog).filterDate(time[0],time[1]).filterBounds(location).select(bands)\n",
    "        return dataset\n",
    "\n",
    "    # function to derive VIs\n",
    "    def calculateVI(image):\n",
    "        '''This method calculates different vegetation indices in a image collection and adds their values as new bands'''\n",
    "\n",
    "        # defining dictionary of bands Sentinel-2 \n",
    "        dict_bands = {\n",
    "\n",
    "            \"blue\"  :  'B2',                              #Blue band                        \n",
    "            \"green\" :  'B3',                              #Green band\n",
    "            \"red\"   :  'B4',                              #Red band\n",
    "            \"red1\"  :  'B5',                              #Red-edge spectral band   \n",
    "            \"red2\"  :  'B6',                              #Red-edge spectral band\n",
    "            \"red3\"  :  'B7',                              #Red-edge spectral band    \n",
    "            \"NIR\"   :  'B8',                              #Near-infrared band\n",
    "            \"NIRn\"  :  'B8A',                             #Near-infrared narrow\n",
    "            \"WV\"    :  'B9',                              #Water vapour\n",
    "            \"SWIR1\" :  'B11',                             #Short wave infrared 1\n",
    "            \"SWIR2\" :  'B12',                             #Short wave infrared 2\n",
    "        }\n",
    "\n",
    "        # specify bands \n",
    "        dict  = dict_bands\n",
    "        blue  = dict[\"blue\"]                              #Blue band                        \n",
    "        green = dict[\"green\"]                             #Green band\n",
    "        red   = dict[\"red\"]                               #Red band\n",
    "        red1  = dict[\"red1\"]                              #Red-edge spectral band    \n",
    "        red2  = dict[\"red2\"]                              #Red-edge spectral band\n",
    "        red3  = dict[\"red3\"]                              #Red-edge spectral band\n",
    "        NIR   = dict[\"NIR\"]                               #Near-infrared band\n",
    "        NIRn  = dict[\"NIRn\"]                              #Near-infrared band\n",
    "        WV    = dict[\"WV\"]                                #Water vapour\n",
    "        SWIR1 = dict[\"SWIR1\"]                             #Short wave infrared 1\n",
    "        SWIR2 = dict[\"SWIR2\"]                             #Short wave infrared 2\n",
    "\n",
    "        bands_for_expressions = {\n",
    "\n",
    "            'blue'  : image.select(blue).divide(10000),\n",
    "            'green' : image.select(green).divide(10000), \n",
    "            'red'   : image.select(red).divide(10000),\n",
    "            'red1'  : image.select(red1).divide(10000), \n",
    "            'red2'  : image.select(red2).divide(10000),\n",
    "            'red3'  : image.select(red3).divide(10000), \n",
    "            'NIR'   : image.select(NIR).divide(10000),\n",
    "            'NIRn'  : image.select(NIRn).divide(10000),\n",
    "            'WV'    : image.select(WV).divide(10000),\n",
    "            'SWIR1' : image.select(SWIR1).divide(10000),\n",
    "            'SWIR2' : image.select(SWIR2).divide(10000)}\n",
    "\n",
    "        # greeness related indices\n",
    "        # NDVI                                                                             (Rouse et al., 1974)\n",
    "        NDVI  = image.normalizedDifference([NIR, red]).rename(\"NDVI\") \n",
    "        # EVI                                                                             \n",
    "        EVI   = image.expression('2.5*(( NIR - red ) / ( NIR + 6 * red - 7.5 * blue + 1 ))', \n",
    "                bands_for_expressions).rename(\"EVI\")\n",
    "        # EVI2                                                                             (Jiang et al., 2008)\n",
    "        EVI2  = image.expression('2.5*(( NIR - red ) / ( NIR + 2.4 * red + 1 ))', \n",
    "                bands_for_expressions).rename(\"EVI2\")\n",
    "\n",
    "        # greeness related indices with Sentinel-2 narrow bands / Red-edge\n",
    "        # Clr\n",
    "        CLr  = image.expression('(red3/red1)-1', bands_for_expressions).rename(\"CLr\")\n",
    "        # Clg\n",
    "        Clg  = image.expression('(red3/green)-1', bands_for_expressions).rename(\"CLg\")\n",
    "        # MTCI\n",
    "        MTCI = image.expression('(red2-red1)/(red1-red)', bands_for_expressions).rename(\"MTCI\")\n",
    "        # MNDVI                                                                            (Add reference)\n",
    "        MNDVI = image.normalizedDifference([red3, red1]).rename(\"MNDVI\")    \n",
    "\n",
    "        # water related indices\n",
    "        # MNDWI                                                                            (Add reference)\n",
    "        MNDWI = image.normalizedDifference([green, SWIR1]).rename(\"MNDWI\")    \n",
    "        # NDWI OR LSWI or NDII or NDMI                                                     (Add reference)\n",
    "        LSWI  = image.normalizedDifference([NIR, SWIR1]).rename(\"LSWI\")\n",
    "        # NDII                                                                             (Hunt & Qu, 2013)\n",
    "        NDII   = image.normalizedDifference([NIR, SWIR2]).rename(\"NDII\")\n",
    "\n",
    "        image = image.addBands(NDVI).addBands(EVI).addBands(EVI2)\n",
    "        image = image.addBands(CLr).addBands(Clg).addBands(MTCI).addBands(MNDVI)\n",
    "        image = image.addBands(MNDWI).addBands(LSWI).addBands(NDII)\n",
    "\n",
    "        return image  \n",
    "\n",
    "    # cloud coverage filter function\n",
    "    def cloud_filter(collection, cloud_coverage_metadata_name, threshold):\n",
    "        collection_cf = collection.filterMetadata(cloud_coverage_metadata_name,'less_than', threshold)\n",
    "        # Show messages\n",
    "        print('The maximun cloud coverage in the image is:', max_cloud_coverage)\n",
    "        print('The original size of the collection is', collection.size().getInfo())\n",
    "        # print(s2.first().getInfo())\n",
    "        print('The filtered size of the collection is', collection_cf.size().getInfo(),'\\n')\n",
    "        return collection_cf\n",
    "    \n",
    "    def local_cloud_filter(s2, aoi, LOCAL_CLOUD_THRESH):\n",
    "        # Describe functions\n",
    "        # Function to scale the reflectance bands\n",
    "        def apply_scale_factors_s2(image):\n",
    "            optical_bands = image.select(['B.']).divide(10000)\n",
    "            thermal_bands = image.select(['B.*']).divide(10000)\n",
    "            return image.addBands(optical_bands, None, True).addBands(thermal_bands, None, True)\n",
    "\n",
    "        # Function to create mask with cirrus clouds and cirrus pixels\n",
    "        def extract_bit_s2_10_11(image):\n",
    "            bit_position_clouds = 10\n",
    "            bit_position_cirrus = 11\n",
    "\n",
    "            # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "            cloud_bit_mask = 1 << bit_position_clouds\n",
    "            cirrus_bit_mask = 1 << bit_position_cirrus\n",
    "\n",
    "            mask_clouds = image.bitwiseAnd(cloud_bit_mask).rightShift(bit_position_clouds)\n",
    "            mask_cirrus = image.bitwiseAnd(cirrus_bit_mask).rightShift(bit_position_cirrus)\n",
    "            mask = mask_clouds.add(mask_cirrus)\n",
    "            return mask\n",
    "\n",
    "        # Function to mask pixels with high reflectance in the blue (B2) band. The function creates a QA band\n",
    "        def b2_mask(image):\n",
    "            B2Threshold = 0.2\n",
    "            B2Mask = image.select('B2').gt(B2Threshold)\n",
    "            return image.addBands(B2Mask.rename('B2Mask'))\n",
    "\n",
    "        # Function to create a band with ones\n",
    "        def make_ones(image):\n",
    "            # Create a band with ones\n",
    "            ones_band = image.select('B2').divide(image.select('B2'))\n",
    "            return image.addBands(ones_band.rename('Ones'))\n",
    "\n",
    "        # Function to calculate area\n",
    "        def get_area(img):\n",
    "            cloud_area = make_ones(img).select('Ones').multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=30).values().get(0)\n",
    "            return img.set('area_image', ee.Number(cloud_area))\n",
    "\n",
    "        # Function to get local cloud percentage with QA band\n",
    "        def get_local_cloud_percentage(img):\n",
    "            error_margin = 1 # meter\n",
    "            cloud_area = extract_bit_s2_10_11(img.select('QA60')).multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=60).values().get(0)\n",
    "            return img.set('local_cloud_percentage', ee.Number(cloud_area).divide(aoi.area(maxError=error_margin)).multiply(100).round())\n",
    "\n",
    "        # Function to get local cloud percentage with QA and area of image band\n",
    "        def get_local_cloud_percentage_area_image(img):\n",
    "            area_image = img.get('area_image')\n",
    "            cloud_area = extract_bit_s2_10_11(img.select('QA60')).multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=60).values().get(0)\n",
    "            return img.set('local_cloud_percentage_ai', ee.Number(cloud_area).divide(ee.Number(area_image)).multiply(100).round())\n",
    "\n",
    "        # Function to get local cloud percentage with B2 and area of image band\n",
    "        def get_local_cloud_percentage_area_image_b2(img):\n",
    "            area_image = img.get('area_image')\n",
    "            cloud_area = b2_mask(img).select('B2Mask').multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=60).values().get(0)\n",
    "            return img.set('local_cloud_percentage_ai_b2', ee.Number(cloud_area).divide(ee.Number(area_image)).multiply(100).round())\n",
    "\n",
    "        # def add_ndvi(image):\n",
    "        #     # Calculate NDVI\n",
    "        #     ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "        #     return image.addBands(ndvi)\n",
    "\n",
    "        s2 = s2.filterBounds(aoi).map(lambda image: image.clip(aoi)).map(apply_scale_factors_s2) #.map(add_ndvi)\n",
    "        \n",
    "        # Processing\n",
    "        # Calculate area\n",
    "        s2 = s2.map(get_area)\n",
    "        # Calculate local cloud percentage with QA band\n",
    "        s2 = s2.map(get_local_cloud_percentage)\n",
    "        # Calculate local cloud percentage with QA band and area image band\n",
    "        s2 = s2.map(get_local_cloud_percentage_area_image)\n",
    "        # Calculate local cloud percentage with B2 band and area image band\n",
    "        s2 = s2.map(get_local_cloud_percentage_area_image_b2)\n",
    "        # Filter images\n",
    "        s2_filtered = s2.filter(ee.Filter.lte('local_cloud_percentage_ai', LOCAL_CLOUD_THRESH))\n",
    "        s2_filtered = s2_filtered.filter(ee.Filter.lte('local_cloud_percentage_ai_b2', LOCAL_CLOUD_THRESH))\n",
    "\n",
    "        # Show messages\n",
    "        print('The maximun cloud coverage in the area is:', LOCAL_CLOUD_THRESH)\n",
    "        print('The original size of the collection is', s2.size().getInfo())\n",
    "        # print(s2.first().getInfo())\n",
    "        print('The filtered size of the collection is', s2_filtered.size().getInfo(),'\\n')\n",
    "        \n",
    "        return s2_filtered \n",
    "\n",
    "    # function for masking non-vegetation areas\n",
    "    def maskS2nonvegetation(image):\n",
    "\n",
    "            qa    = image.select('QA60')\n",
    "            scl   = image.select('SCL')\n",
    "            ndvi  = image.select('NDVI')\n",
    "            mndvi = image.select('MNDVI')\n",
    "\n",
    "            cloudBitMask = 1 << 10\n",
    "            cirrusBitMask = 1 << 11\n",
    "\n",
    "            #vegetationMask1 = 4 # vegetation\n",
    "            #vegetationMask2 = 5 # non-vegetated\n",
    "            #vegetationMask3 = 6 # water\n",
    "            #vegetationMask4 = 7 # unclassified\n",
    "            #vegetationMask5 = 11 # snow\n",
    "\n",
    "            # this mask selects vegetation + non-vegetated + water + unclassified + areas with VIs (NDVI and MNDVI) greater that a threshold set in the configuration file\n",
    "            mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(7)).Or(scl.eq(11)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "            # mask = scl.eq(4).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "            # mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "\n",
    "            vegetation = image.updateMask(mask)\n",
    "\n",
    "            return vegetation\n",
    "    \n",
    "    # get inpu data\n",
    "    # create a only file per year identified in the input files\n",
    "    years = year_list\n",
    "\n",
    "    # create range according to data in the input datafiles   \n",
    "    start   = '%s-01-01'   %(years[0])                                                                                          \n",
    "    end     = '%s-12-31'   %(years[-1])                                            \n",
    "    timeSD  = [start, end]\n",
    "\n",
    "    # create coordinates of the eddy covariance tower\n",
    "    lon_lat =  [longitude, latitude]         \n",
    "    point   = ee.Geometry.Point(lon_lat)\n",
    "\n",
    "    # collections google earth engine    \n",
    "    COPERNICUS_S2_L2A = collection #Multi-spectral surface reflectances (https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR)       \n",
    "    COPERNICUS_S2_bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'AOT', 'WVP', 'SCL', 'TCI_R', 'TCI_G', 'TCI_B', 'QA10', 'QA20', 'QA60']\n",
    "\n",
    "    # applying functions \n",
    "    # request of catalogues \n",
    "    S2_VI     = load_catalog(COPERNICUS_S2_L2A, timeSD, point, COPERNICUS_S2_bands)\n",
    "\n",
    "    # filter cloud coverage\n",
    "    cloud_coverage_metadata_name = 'CLOUDY_PIXEL_PERCENTAGE'                     # name of metadata property indicating cloud coverage in %\n",
    "\n",
    "    # applying cloud filter \n",
    "    S2_VI = cloud_filter(S2_VI, cloud_coverage_metadata_name, max_cloud_coverage)   # max cloud coverage defined in the Config file\n",
    "\n",
    "    # apply cloud local filter\n",
    "    S2_VI = local_cloud_filter(S2_VI, aoi, local_cloud_coverage)\n",
    "\n",
    "    # calculation of vegetation indices for the collection\n",
    "    S2_VI = S2_VI.map(calculateVI)\n",
    "\n",
    "    # applying mask \n",
    "    S2_VI = S2_VI.map(maskS2nonvegetation)\n",
    "\n",
    "    return S2_VI, point\n",
    "\n",
    "def get_ecosystem_geometry(training_dataset,number_clusters,training_scale,scale_getRegion, vector_scale, point, ic, bands, ecosystem_extent):\n",
    "    #https://code.earthengine.google.com/2b95fd6462c6c906d4ed9a74fae51bf4\n",
    "    Region    =  point.buffer(ecosystem_extent/2)\n",
    "    inputML   =  ic.select(bands).median().clip(Region)\n",
    "\n",
    "    # This trainning function takes pixes or pixels even in larger region than inputML\n",
    "    training  = inputML.sample(region=Region, scale=training_scale, numPixels=training_dataset)\n",
    "    clusterer = ee.Clusterer.wekaKMeans(number_clusters).train(training)\n",
    "\n",
    "    result    = inputML.cluster(clusterer)\n",
    "    results_colect  = ee.ImageCollection([result])\n",
    "    df_clus = results_colect.getRegion(point, scale_getRegion).getInfo()\n",
    "    df_clus = pd.DataFrame(df_clus)\n",
    "    headers = df_clus.iloc[0]\n",
    "    df_clus = pd.DataFrame(df_clus.values[1:], columns=headers).set_index('id')\n",
    "    cluster_ecosystem = df_clus['cluster'][0]\n",
    "    results_shp = result.reduceToVectors(scale=vector_scale, bestEffort=True)\n",
    "\n",
    "    def classification(weka, num):\n",
    "        class_vegetation = weka.select('label').filter(ee.Filter.eq('label', num))\n",
    "        return class_vegetation\n",
    "\n",
    "    cluster_name = []\n",
    "    for i in range(number_clusters):\n",
    "        globals()['cluster_%s'%i] = classification(results_shp, i).union(1).geometry()\n",
    "        cluster_name.append(globals()['cluster_%s'%i])\n",
    "\n",
    "    cluster_ecosystem_geometry  = cluster_name[cluster_ecosystem]\n",
    "\n",
    "    et_image = ee.ImageCollection([result.eq(cluster_ecosystem)])\n",
    "\n",
    "    return inputML, et_image, cluster_ecosystem_geometry \n",
    "\n",
    "def get_ecosystem_map(latitude,longitude,cluster_ecosystem_geometry, inputML, directory_maps, site, year, point, fetch_70):\n",
    "    # define a method for displaying Earth Engine image tiles on a folium map.\n",
    "    def add_ee_layer(self, ee_object, vis_params, name):\n",
    "        try:    \n",
    "\n",
    "            # display ee.Image()\n",
    "            if isinstance(ee_object, ee.image.Image):    \n",
    "                map_id_dict = ee.Image(ee_object).getMapId(vis_params)\n",
    "                folium.raster_layers.TileLayer(\n",
    "                tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "                attr = 'Google Earth Engine',\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True\n",
    "                ).add_to(self)\n",
    "\n",
    "            # display ee.ImageCollection()\n",
    "            elif isinstance(ee_object, ee.imagecollection.ImageCollection):    \n",
    "                ee_object_new = ee_object.mosaic()\n",
    "                map_id_dict = ee.Image(ee_object_new).getMapId(vis_params)\n",
    "                folium.raster_layers.TileLayer(\n",
    "                tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "                attr = 'Google Earth Engine',\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True\n",
    "                ).add_to(self)\n",
    "\n",
    "            # display ee.Geometry()\n",
    "            elif isinstance(ee_object, ee.geometry.Geometry):    \n",
    "                folium.GeoJson(\n",
    "                data = ee_object.getInfo(),\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True,\n",
    "                style_function=lambda x:vis_params\n",
    "            ).add_to(self)\n",
    "\n",
    "            # display ee.FeatureCollection()\n",
    "            elif isinstance(ee_object, ee.featurecollection.FeatureCollection):  \n",
    "                ee_object_new = ee.Image().paint(ee_object, 0, 2)\n",
    "                map_id_dict = ee.Image(ee_object_new).getMapId(vis_params)\n",
    "                folium.raster_layers.TileLayer(\n",
    "                tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "                attr = 'Google Earth Engine',\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True\n",
    "            ).add_to(self)\n",
    "\n",
    "        except:\n",
    "            print(\"Could not display {}\".format(name))\n",
    "\n",
    "    # add EE drawing method to folium.\n",
    "    folium.Map.add_ee_layer = add_ee_layer\n",
    "\n",
    "    # Add custom basemaps to folium\n",
    "    basemaps = {\n",
    "        'Google Maps': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Maps',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Google Satellite': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Satellite',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Google Terrain': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=p&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Terrain',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Google Satellite Hybrid': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Satellite',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Esri Satellite': folium.TileLayer(\n",
    "            tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "            attr = 'Esri',\n",
    "            name = 'Esri Satellite',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        )\n",
    "    }\n",
    "\n",
    "    directory_maps = os.path.join(directory_maps, site)\n",
    "    os.makedirs(directory_maps, exist_ok=True) \n",
    "\n",
    "    # Mapping with folium\n",
    "    # a) create a folium map object.\n",
    "    my_map = folium.Map(location= [latitude,longitude], zoom_start=12)\n",
    "    # b) add custom basemaps\n",
    "    basemaps['Esri Satellite'].add_to(my_map)\n",
    "    basemaps['Google Satellite Hybrid'].add_to(my_map)\n",
    "    # c) set visualization parameters.\n",
    "    vis_params = {\n",
    "    'min': 0,\n",
    "    'max': 4000,\n",
    "    'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}\n",
    "    # d) display Geometry\n",
    "    vis_params_geometry = dict(color='red', weight=2, opacity=10, fillColor='red')\n",
    "    my_map.add_ee_layer(cluster_ecosystem_geometry,  vis_params_geometry , 'Ecosystem area')\n",
    "    vis_params_geometry = dict(color='blue', weight=2, opacity=10, fillColor='red')\n",
    "    my_map.add_ee_layer(point,  vis_params_geometry , 'Eddy covariance tower')\n",
    "    my_map.add_ee_layer(point.buffer(fetch_70),  vis_params_geometry , 'Eddy covariance fetch')\n",
    "    # d) display ee.Image\n",
    "    dataset        = inputML.select('NDVI')\n",
    "    vis_params = {\n",
    "        'min': 0.5,\n",
    "        'max': 1.0,\n",
    "        'palette': ['red', 'white', 'green']\n",
    "    }\n",
    "    my_map.add_ee_layer(dataset, vis_params, 'NDVI')\n",
    "    # e) add a layer control panel to the map.\n",
    "    my_map.add_child(folium.LayerControl())\n",
    "    plugins.Fullscreen().add_to(my_map)\n",
    "    \n",
    "    my_map.save(os.path.join(directory_maps, f'{site} - Ecosystem map ({year}).html'))\n",
    "    return my_map\n",
    "\n",
    "def get_et_df(et_array, year):\n",
    "    df = pd.DataFrame(et_array[1:], columns=et_array[0])\n",
    "    df = df.iloc[:,1:]\n",
    "    df['time'] =  pd.to_datetime(f'{year}')\n",
    "    df.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def plot_save_et(image, aoi, site, year, directory_maps, mse, test_r2, mae, rmse): \n",
    "    print(f'Saving Uncertainty product for {year}\\n')  \n",
    "\n",
    "    directory_maps = os.path.join(directory_maps, site)\n",
    "    os.makedirs(directory_maps, exist_ok=True) \n",
    "\n",
    "    et_sample = image.getRegion(aoi, 10).getInfo()\n",
    "    df_et =  get_et_df(et_sample, year)\n",
    "    ds = df_et.to_xarray()\n",
    "\n",
    "    crs = CRS.from_epsg(4326)\n",
    "    ds.attrs['crs'] = crs.to_string()\n",
    "    ds.attrs['title'] = f'Gross Primary Production Uncertainty Map - {year}'\n",
    "    ds.attrs['description'] = 'This COG file represents the uncertainty in Gross Primary Production estimates for the specified year.'\n",
    "    ds.attrs['source'] = site\n",
    "    ds.attrs['year'] = year\n",
    "    ds.attrs['MSE'] = mse\n",
    "    ds.attrs['MAE'] = mae\n",
    "    ds.attrs['RMSE'] = rmse\n",
    "    ds.attrs['R^2'] = test_r2\n",
    "\n",
    "    ds['cluster'].to_netcdf(os.path.join(directory_maps, f'{site.lower()}_gpp_uncertainty_map_{year}.nc'))\n",
    "\n",
    "    da = ds['cluster'].isel(time=0)\n",
    "    da.attrs['crs'] = crs.to_string()\n",
    "    da.attrs['title'] = f'Gross Primary Production Uncertainty Map - {year}'\n",
    "    da.attrs['description'] = 'This COG file represents the uncertainty in Gross Primary Production estimates for the specified year.'\n",
    "    da.attrs['source'] = site\n",
    "    da.attrs['year'] = year\n",
    "    da.attrs['MSE'] = mse\n",
    "    da.attrs['MAE'] = mae\n",
    "    da.attrs['RMSE'] = rmse\n",
    "    da.attrs['R^2'] = test_r2\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    da.plot()\n",
    "    plt.title(f'{site} - Gross Primary Production (GPP) - Uncertainty Map - {year}')\n",
    "    plt.savefig(os.path.join(directory_maps, f'{site.lower()}_gpp_uncertainty_map_{year}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "\n",
    "    da.rio.to_raster(\n",
    "        os.path.join(directory_maps, f'{site.lower()}_gpp_uncertainty_map_{year}.tif'),\n",
    "        driver='COG',\n",
    "        compress='deflate',\n",
    "        nodata=da.attrs.get('_FillValue', None),\n",
    "        dtype=da.dtype.name\n",
    "    )\n",
    "\n",
    "def get_testing_data(directory_data, filename, expected_columns, gpp_column):\n",
    "    env_df = pd.read_csv(os.path.join(directory_data, filename), index_col='TIMESTAMP', parse_dates=['TIMESTAMP'])\n",
    "    env_testing = env_df[expected_columns]\n",
    "    gpp_testing = env_df[gpp_column]\n",
    "    return env_testing, gpp_testing\n",
    "\n",
    "def predict_gpp_df(df, model_file):\n",
    "    print('Testing Gross Primary Production')\n",
    "    loaded_model = XGBRegressor()\n",
    "    loaded_model.load_model(model_file)\n",
    "    y_pred = loaded_model.predict(df)\n",
    "    df['GPP_predicted'] = y_pred\n",
    "    return df\n",
    "\n",
    "def get_performance(df, year):\n",
    "    df = df.reset_index()\n",
    "    df = df[df['TIMESTAMP'].dt.year == int(year)]\n",
    "    y_test = df['GPP_testing']\n",
    "    y_pred = df['GPP_predicted']\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print('Mean Squared Error:', mse)\n",
    "    print('Root Mean Squared Error:', rmse)\n",
    "    print('MAE:', mae)\n",
    "    print(\"Test R^2 Score:\", test_r2,'\\n')\n",
    "\n",
    "    return df, mse, test_r2, mae, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "site_list = r'D:\\Proyectos2024\\Agame\\Output\\sites_selection\\sites_table_filtered_4y.csv'\n",
    "model_file = r\"D:\\Proyectos2024\\Agame\\Output\\model_12_sites_era\\xgboost_model_12_sites_era.json\"\n",
    "directory_data = r'D:\\Proyectos2024\\Agame\\Output\\Tables'\n",
    "directory_maps = r'D:\\Proyectos2024\\Agame\\Output\\Maps_test_mask'\n",
    "\n",
    "expected_columns = ['CLr', 'EVI', 'EVI2', 'LSWI', 'LW_IN_ERA','LW_IN_JSB_ERA', 'MNDVI', 'MNDWI', 'NDII', 'NDVI', 'PA_ERA', 'P_ERA', 'SW_IN_ERA', 'TA_ERA', 'VPD_ERA', 'WS_ERA', 'biom_deciduous broadleaf forests', 'biom_evergreen needleleaf forests', 'biom_grasslands', 'biom_mixed forests', 'canopy_height', 'elevation', 'fall', 'lat', 'lon', 'spring', 'summer', 'winter'] \n",
    "expected_columns = ['CLr', 'EVI', 'EVI2', 'LSWI', 'LW_IN_ERA', 'LW_IN_JSB_ERA', 'MNDVI', 'MNDWI', 'NDII', 'NDVI', 'PA_ERA', 'P_ERA', 'SW_IN_ERA', 'TA_ERA', 'VPD_ERA', 'WS_ERA', 'biom_deciduous broadleaf forests', 'biom_evergreen needleleaf forests', 'biom_grasslands', 'biom_mixed forests', 'canopy_height', 'elevation', 'fall', 'lat', 'lon', 'spring', 'summer', 'winter', 'day', 'month']\n",
    "expected_columns = ['CLr', 'EVI', 'EVI2', 'LSWI', 'LW_IN_ERA', 'LW_IN_JSB_ERA', 'MNDVI', 'MNDWI', 'NDII', 'NDVI', 'PA_ERA', 'P_ERA', 'SW_IN_ERA', 'TA_ERA', 'VPD_ERA', 'WS_ERA', 'biom_deciduous broadleaf forests', 'biom_evergreen needleleaf forests', 'biom_grasslands', 'biom_mixed forests', 'canopy_height', 'day', 'elevation', 'fall', 'lat', 'lon', 'month', 'spring', 'summer', 'winter']\n",
    "date_range_values = ['2021-01-01','2021-12-31'] \n",
    "date_range_values = ['2021-07-20','2021-07-21'] \n",
    "\n",
    "# MGRS_TILE = '34VFP' #'35VLJ'\n",
    "MGRS_TILE = None\n",
    "\n",
    "max_cloud_coverage   = 100\n",
    "local_cloud_coverage = 0\n",
    "training_dataset = 10000\n",
    "# number_clusters = 2 # Torgnon = 3\n",
    "training_scale = 10\n",
    "scale_getRegion = 10\n",
    "vector_scale = 10\n",
    "ecosystem_extent = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "general = [\n",
    "'lat', \n",
    "'lon', \n",
    "'elevation', \n",
    "'canopy_height', \n",
    "'biom_evergreen needleleaf forests',\n",
    "'biom_grasslands',\n",
    "'biom_deciduous broadleaf forests',\n",
    "'biom_mixed forests',\n",
    "'winter',\n",
    "'spring', \n",
    "'summer', \n",
    "'fall']\n",
    "\n",
    "era_var = [\n",
    " 'LW_IN_ERA',\n",
    " 'LW_IN_JSB_ERA',\n",
    " 'PA_ERA',\n",
    " 'P_ERA',\n",
    " 'SW_IN_ERA',\n",
    " 'TA_ERA',\n",
    " 'VPD_ERA',\n",
    " 'WS_ERA']\n",
    "\n",
    "bands = [\n",
    " 'B1',\n",
    " 'B2',\n",
    " 'B3',\n",
    " 'B4',\n",
    " 'B5',\n",
    " 'B6',\n",
    " 'B7',\n",
    " 'B8',\n",
    " 'B8A', \n",
    " 'B9',\n",
    " 'B11',\n",
    " 'B12']\n",
    "\n",
    "sentinel = [\n",
    " 'CLr',\n",
    " 'EVI',\n",
    " 'EVI2',\n",
    " 'LSWI', \n",
    " 'MNDVI',\n",
    " 'MNDWI',\n",
    " 'NDII',\n",
    " 'NDVI']\n",
    "\n",
    "s2_era_general = sentinel.copy()\n",
    "s2_era_general.extend(era_var)\n",
    "s2_era_general.extend(general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['CH-Dav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_name_list, files_list, df_sites = sites_info_csv(site_list, directory_data)\n",
    "site_name_list = site_name_list[2:3]\n",
    "files_list = files_list[2:3]\n",
    "site_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating products for CH-Dav\n",
      "\n",
      "The area of the site is 10485.02292974303 square meters\n",
      "The area of the site is 0.010485022929743031 square kilometers\n",
      "\n",
      "The area of the site is below 1 square kilometer. A new area with a minimun of 1 square kilometer will be created\n",
      "The new area of the site is 994493.1812844094 square meters\n",
      "The mew area of the site is 0.9944931812844093 square kilometers\n",
      "The site geometry is ready to extract Earth Observation data\n",
      "\n",
      "Testing Gross Primary Production\n",
      "Period: 2021-07-20, 2021-07-21\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210720T101559_20210720T101617_T32TNS']\n",
      "Predicting Gross Primary Production\n",
      "Saving Gross Primary Production products\n",
      "\n",
      "Calculating uncerstainty product for CH-Dav in 2021\n",
      "\n",
      "Mean Squared Error: 1.171663335308479\n",
      "Root Mean Squared Error: 1.0824339865823132\n",
      "MAE: 0.8545513192652266\n",
      "Test R^2 Score: 0.7512031580490003 \n",
      "\n",
      "The maximun cloud coverage in the image is: 100\n",
      "The original size of the collection is 73\n",
      "The filtered size of the collection is 73 \n",
      "\n",
      "The maximun cloud coverage in the area is: 0\n",
      "The original size of the collection is 73\n",
      "The filtered size of the collection is 14 \n",
      "\n",
      "Saving Uncertainty product for 2021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(site_name_list)):\n",
    "\n",
    "    print(f'Calculating products for {site_name_list[index]}\\n')\n",
    "\n",
    "    site = site_name_list[index]\n",
    "    filename = files_list[index]\n",
    "    df_classes = df_sites.loc[df_sites['sites_ids'] == site]\n",
    "    number_clusters = df_classes['classes'].values.tolist()[0]\n",
    "    fetch_70 = df_classes['FETCH_70'].values.tolist()[0]\n",
    "\n",
    "    boundaries, latitude, longitude, information = get_coordinates_area(df_sites, site)\n",
    "    m, gdf = map_coordinates_area(df_sites, boundaries, site)\n",
    "    Map, aoi = get_gee_area_from_gpp_multipolygon_single_polygon(boundaries, gdf, 6)\n",
    "\n",
    "    date_range = pd.date_range(start=date_range_values[0], end=date_range_values[1], freq='D')\n",
    "    dates_list = date_range.strftime('%Y-%m-%d').tolist()\n",
    "    year_list = get_unique_years(dates_list)\n",
    "\n",
    "    env_testing, gpp_testing = get_testing_data(directory_data, filename, expected_columns, 'GPP_DT_VUT_REF')\n",
    "    gpp_predicted = predict_gpp_df(env_testing, model_file)\n",
    "    gpp_predicted['GPP_testing'] = gpp_testing \n",
    "\n",
    "    for index in range(len(dates_list)-1):\n",
    "        period = [dates_list[index], dates_list[index+1]]\n",
    "        print(f\"Period: {dates_list[index]}, {dates_list[index+1]}\")\n",
    "        \n",
    "        try:\n",
    "            try:\n",
    "                number_img = 0\n",
    "                s2_array, s2 = get_s2_array(period,aoi,sentinel, number_img, MGRS_TILE=MGRS_TILE,cloud_percentage=100,resolution=10)\n",
    "                s2_df = get_s2_df(s2_array)\n",
    "                env_df = get_environmental_data(directory_data, filename, sentinel, bands, general)\n",
    "                df_merged = merge_s2_env_data(s2_df, env_df, expected_columns)\n",
    "                ds_gpp = predict_gpp(df_merged, model_file)\n",
    "                plot_save_gpp(ds_gpp, site, period, directory_maps)\n",
    "\n",
    "            except Exception as e:\n",
    "                # Handle any other exceptions\n",
    "                print(f\"An unexpected error occurred: {e}\")\n",
    "                print('Trying with second error in collection')\n",
    "                number_img = 1\n",
    "                s2_array, s2 = get_s2_array(period,aoi,sentinel, number_img, MGRS_TILE=MGRS_TILE,cloud_percentage=100,resolution=10)\n",
    "                s2_df = get_s2_df(s2_array)\n",
    "                env_df = get_environmental_data(directory_data, filename, sentinel, bands, general)\n",
    "                df_merged = merge_s2_env_data(s2_df, env_df, expected_columns)\n",
    "                ds_gpp = predict_gpp(df_merged, model_file)\n",
    "                plot_save_gpp(ds_gpp, site, period, directory_maps)\n",
    "\n",
    "        except ee.EEException as ee_error:\n",
    "            print(f\"Earth Engine Exception: {ee_error}\\n\")\n",
    "\n",
    "    for year in year_list:\n",
    "        print(f'Calculating uncerstainty product for {site} in {year}\\n')\n",
    "\n",
    "        df, mse, test_r2, mae, rmse = get_performance(gpp_predicted, year)\n",
    "\n",
    "        ic, point = get_collection_without_clouds('COPERNICUS/S2_SR_HARMONIZED',[year],aoi,longitude,latitude,max_cloud_coverage,local_cloud_coverage)\n",
    "        bands = ic.first().bandNames().getInfo() \n",
    "        inputML, cluster_ecosystem_image, cluster_ecosystem_geometry = get_ecosystem_geometry(training_dataset,number_clusters,training_scale,scale_getRegion, vector_scale, point, ic, bands, ecosystem_extent)\n",
    "        ecosystem_map = get_ecosystem_map(latitude,longitude,cluster_ecosystem_geometry, inputML, directory_maps, site, year, point, fetch_70)\n",
    "        # Map = map_image(cluster_ecosystem_image.first(), aoi, \"cluster\", \"Cluster\")\n",
    "        plot_save_et(cluster_ecosystem_image,aoi, site, year, directory_maps, mse, test_r2, mae, rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deltares_GPP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
