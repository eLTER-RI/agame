{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGAME Workflow. Get flux data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from icoscp.station import station\n",
    "from icoscp.dobj import Dobj\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import folium\n",
    "import requests\n",
    "\n",
    "# from icoscp_core.icos import auth\n",
    "# auth.init_config_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_flux_df(file_path):\n",
    "    print('\\nReading:', file_path)\n",
    "\n",
    "    df = pd.read_csv(file_path, na_values=-9999)\n",
    "    original_num_columns = df.shape[1]\n",
    "    cols_to_drop = df.columns[df.isna().all()].tolist()\n",
    "    num_cols_dropped = len(cols_to_drop)\n",
    "\n",
    "    print(f\"Original number of columns: {original_num_columns}\")\n",
    "    print(f\"Number of columns dropped: {num_cols_dropped}\")\n",
    "    print(f\"Columns dropped: {cols_to_drop}\\n\")\n",
    "\n",
    "    df_cleaned = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "def filter_era_columns(sites_table, df, list_col, nan_files):\n",
    "    counts = Counter(list_col)\n",
    "    list_col_in_all = set([item for item in list_col if counts[item] == (len(sites_table)-len(nan_files))])\n",
    "    print(f\"Number of columns available in all files: {len(list_col_in_all)}\\n\")\n",
    "\n",
    "    filtered_list_col_in_all = sorted([item for item in list_col_in_all if not (item.startswith('NEE') or \n",
    "                                                                                item.startswith('GPP') or \n",
    "                                                                                item.startswith('TIMESTAMP') or\n",
    "                                                                                item.endswith('_QC') or \n",
    "                                                                                item.endswith('_METHOD') or \n",
    "                                                                                item.startswith('RECO'))])\n",
    "\n",
    "    combined_var = sorted([item for item in list_col_in_all  if item.endswith('_F')])\n",
    "    era_var = sorted([item for item in list_col_in_all  if item.endswith('_ERA')])\n",
    "    mds_var = sorted([item for item in list_col_in_all  if item.endswith('_MDS')])\n",
    "\n",
    "    era_var.insert(0, 'GPP_DT_VUT_REF')\n",
    "    df = df[era_var]\n",
    "\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "def filter_flux_columns(data_directory, sites_table):\n",
    "\n",
    "    list_col = []\n",
    "    nan_files = []\n",
    "\n",
    "    for index, row in sites_table.iterrows():\n",
    "        print(f\"\\nSite ID: {row['sites_ids']}\")\n",
    "\n",
    "        # Unzip files if needed\n",
    "        # file_path = os.path.join(data_directory, row['File name'])\n",
    "        # with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        #     zip_ref.extractall(os.path.join(data_directory, row['sites_folder'])) \n",
    "        #     print(f\"Unzipped: {row['sites_folder']}\")\n",
    "        try:\n",
    "            flux_file_path = os.path.join(data_directory,row['sites_folder'],f\"ICOSETC_{row['sites_ids']}_FLUXNET_DD_L2.csv\" )\n",
    "            flux_df = read_flux_df(flux_file_path)\n",
    "            list_col.extend(flux_df.columns.values.tolist())\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {flux_file_path}\")\n",
    "            nan_files.append({flux_file_path}) \n",
    "\n",
    "    counts = Counter(list_col)\n",
    "    list_col_in_all = set([item for item in list_col if counts[item] == (len(sites_table)-len(nan_files))])\n",
    "    print(f\"Number of columns available in all files: {len(list_col_in_all)}\")\n",
    "\n",
    "    filtered_flux_columns = sorted([item for item in list_col_in_all if not (item.startswith('NEE') or \n",
    "                                                                                item.startswith('GPP') or \n",
    "                                                                                item.startswith('TIMESTAMP') or\n",
    "                                                                                item.endswith('_QC') or \n",
    "                                                                                item.endswith('_METHOD') or \n",
    "                                                                                item.startswith('RECO'))])\n",
    "    \n",
    "    print(f\"Number of columns available in all files without carbon data: {len(filtered_flux_columns)}\\n\")\n",
    "\n",
    "    insitu_cols = ['GPP_DT_VUT_REF', 'NEE_VUT_REF_QC'] + filtered_flux_columns #'GPP_DT_VUT_USTAR50'\n",
    "\n",
    "    return insitu_cols\n",
    "\n",
    "def get_eu_sites(df):\n",
    "    # Fetch country data from the REST Countries API\n",
    "    response = requests.get('https://restcountries.com/v3.1/all')\n",
    "    countries = response.json()\n",
    "\n",
    "    # Extract country codes and their regions\n",
    "    european_country_codes = [country['cca2'] for country in countries if 'region' in country and country['region'] == 'Europe']\n",
    "    df['IsInEurope'] = df['country'].isin(european_country_codes)\n",
    "    df = df[df['IsInEurope'] == True]\n",
    "    df = df.drop(columns=['IsInEurope'])\n",
    "    df\n",
    "    return df\n",
    "\n",
    "def map_sites(df):\n",
    "    # Convert lat/lon to geometry\n",
    "    geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "    # Create a Folium map centered around the average location\n",
    "    m = folium.Map(location=[df['lat'].mean(), df['lon'].mean()], zoom_start=5)\n",
    "\n",
    "    # Add points to the map\n",
    "    for idx, row in gdf.iterrows():\n",
    "        folium.Marker([row['lat'], row['lon']], popup=row['siteType']).add_to(m)\n",
    "\n",
    "    # Display the map\n",
    "    return m\n",
    "\n",
    "def map_sites_with_colors(df):\n",
    "    \n",
    "    # Convert lat/lon to geometry\n",
    "    geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "    # Define a color mapping based on the name\n",
    "    color_mapping = {\n",
    "        'Cropland': 'yellow',\n",
    "        'cropland': 'yellow',\n",
    "        'Forest': 'green',\n",
    "        'forest': 'green',\n",
    "        'Wetland': 'blue',\n",
    "        'wetland': 'blue',\n",
    "        'Grassland': 'magenta',\n",
    "        'grassland': 'magenta',\n",
    "        'Heathland': 'red',\n",
    "        'Urban': 'orange',\n",
    "        'urban': 'orange'\n",
    "    }\n",
    "\n",
    "    # Create a Folium map centered around the average location\n",
    "    m = folium.Map(location=[df['lat'].mean(), df['lon'].mean()], zoom_start=3)\n",
    "\n",
    "    # Add points to the map with different colors\n",
    "    for idx, row in gdf.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            radius=4,\n",
    "            popup=row['siteType'],\n",
    "            color=color_mapping.get(row['siteType'], 'black'),  # Default to black if name not in mapping\n",
    "            fill=True,\n",
    "            fill_color=color_mapping.get(row['siteType'], 'black')\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Display the map\n",
    "    return m\n",
    "\n",
    "def filter_long_ts(df, years):\n",
    "    seconds_in_year = 365.25 * 24 * 60 * 60\n",
    "\n",
    "    df['years_HH'] = df['end_HH'] - df['start_HH'] \n",
    "    df['years_HH']=df['years_HH'].dt.total_seconds() / seconds_in_year\n",
    "\n",
    "    df = df[df['years_HH'] >= years]\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_sites(df, years_ts, output_directory):\n",
    "\n",
    "    df.to_csv(os.path.join(output_directory,'sites_table_complete.csv'), index=False)\n",
    "\n",
    "    df = get_eu_sites(df)\n",
    "    df = filter_long_ts(df, years_ts)\n",
    "    df = df[df['ecosystemType'] != '']\n",
    "    df['siteType'] = df['siteType'].str.strip()\n",
    "    df['ecosystemType'] = df['ecosystemType'].str.strip()\n",
    "    df['siteType'] = df['siteType'].str.lower()\n",
    "    df['ecosystemType'] = df['ecosystemType'].str.lower()\n",
    "\n",
    "    df = df[(df['siteType'] == 'forest') | (df['siteType'] == 'grassland')]\n",
    "\n",
    "    df.to_csv(os.path.join(output_directory,'sites_table_filtered_4years.csv'), index=False) \n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "def read_icos_attributes(index, sites_table, id, output_directory,axs):\n",
    "    myStation = station.get(id)\n",
    "    metadata = myStation.info()\n",
    "    sites_table.loc[index, 'lat'] = metadata['lat']\n",
    "    sites_table.loc[index, 'lon'] = metadata['lon']\n",
    "    sites_table.loc[index, 'country'] = metadata['country']\n",
    "    sites_table.loc[index, 'siteType'] = metadata['siteType']\n",
    "\n",
    "    nan_ids = []\n",
    "    try:\n",
    "        selected_df = myStation.data(2).loc[myStation.data(2)['specLabel'] == \"ETC L2 Fluxnet (half-hourly)\"]\n",
    "        pid = selected_df['dobj'].values.tolist()\n",
    "        dobj = Dobj(pid[0])\n",
    "\n",
    "        start, end = dobj.data['TIMESTAMP'].iloc[[0, -1]]\n",
    "        sites_table.loc[index, 'start_HH'] = start\n",
    "        sites_table.loc[index, 'end_HH'] = end\n",
    "\n",
    "        # ax = dobj.data.plot(x='TIMESTAMP', y='GPP_DT_VUT_REF', grid=True)\n",
    "        # ax.set_title(f'GPP_DT_VUT_REF Over Time at {id} Station')\n",
    "\n",
    "        dobj.data.plot(x='TIMESTAMP', y='GPP_DT_VUT_REF', grid=True, ax=axs[0])\n",
    "        axs[0].set_title(f'GPP_DT_VUT_REF Over Time at {id} Station HH')\n",
    "\n",
    "        # plt.savefig(os.path.join(output_directory, f'GPP_{id}.png'))\n",
    "        # plt.close()\n",
    "\n",
    "        sites_table.loc[index, 'ecosystemType'] = dobj.meta['specificInfo']['acquisition']['station']['specificInfo']['ecosystemType']['label']\n",
    "        dobj = dobj.data\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Flux data not found: {id}\")\n",
    "        nan_ids.append({id})\n",
    "        dobj = pd.DataFrame() \n",
    "    except IndexError:\n",
    "        print(f\"Index out of range for station {id}\")\n",
    "        nan_ids.append(id)\n",
    "        dobj = pd.DataFrame() \n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e}. The key 'GPP_DT_VUT_REF' does not exist for station {id}.\")\n",
    "        nan_ids.append(id)\n",
    "        dobj = pd.DataFrame() \n",
    "\n",
    "    return sites_table, nan_ids, axs, dobj\n",
    "\n",
    "def process_insitu_data(data_directory, sites_folder, id, insitu_cols, sites_table, index, output_directory, axs):\n",
    "\n",
    "    nan_files = []\n",
    "    try:\n",
    "        flux_file_path = os.path.join(data_directory,sites_folder,f\"ICOSETC_{id}_FLUXNET_DD_L2.csv\" )\n",
    "        insitu = pd.read_csv(flux_file_path, index_col='TIMESTAMP', parse_dates=['TIMESTAMP'])\n",
    "        insitu = insitu[insitu_cols]\n",
    "\n",
    "        insitu['TIMESTAMP'] = pd.to_datetime(insitu.index)\n",
    "        # insitu['month'] = pd.DatetimeIndex(insitu['TIMESTAMP']).month\n",
    "        # insitu['day'] = pd.DatetimeIndex(insitu['TIMESTAMP']).day\n",
    "\n",
    "        # start, end = insitu['TIMESTAMP'].iloc[[0, -1]]\n",
    "        # sites_table.loc[index, 'start_DD'] = start\n",
    "        # sites_table.loc[index, 'end_DD'] = end\n",
    "\n",
    "        # insitu.to_csv(os.path.join(output_directory, f\"{id}_preprocessed_{start.strftime('%d%m%Y')}_{end.strftime('%d%m%Y')}.csv\"))\n",
    "\n",
    "        # ax = insitu.plot(x='TIMESTAMP', y='GPP_DT_VUT_REF', grid=True)\n",
    "        # ax.set_title(f'GPP_DT_VUT_REF Over Time at {id} Station')\n",
    "\n",
    "        insitu.plot(x='TIMESTAMP', y='GPP_DT_VUT_REF', grid=True, ax=axs[1])\n",
    "        axs[1].set_title(f'GPP_DT_VUT_REF Over Time at {id} Station (Daily Data)')\n",
    "\n",
    "        # plt.savefig(os.path.join(output_directory, f'GPP_daily_{id}.png'))\n",
    "        # plt.close()\n",
    "\n",
    "        fetch_file_path = os.path.join(data_directory,sites_folder,f\"ICOSETC_{id}_FLUXES_L2.csv\" )\n",
    "        fetch = pd.read_csv(fetch_file_path, index_col='TIMESTAMP_START', parse_dates=['TIMESTAMP_START'], na_values=-9999.0)\n",
    "\n",
    "        sites_table.loc[index, 'FETCH_MAX'] = fetch.describe()['FETCH_MAX'].loc['50%']\n",
    "        sites_table.loc[index, 'FETCH_70'] = fetch.describe()['FETCH_70'].loc['50%']\n",
    "        sites_table.loc[index, 'FETCH_90'] = fetch.describe()['FETCH_90'].loc['50%']\n",
    "\n",
    "        iheight_file_path = os.path.join(data_directory,sites_folder,f\"ICOSETC_{id}_VARINFO_FLUXNET_DD_L2.csv\" )\n",
    "        iheight = pd.read_csv(iheight_file_path)\n",
    "        filtered_df = iheight[iheight['DATAVALUE'] == 'GPP_DT_VUT_REF']\n",
    "        index_gpp = filtered_df.index.values.tolist()[0] \n",
    "        iheight = iheight[index_gpp:index_gpp+5]\n",
    "        iheight_value = iheight[iheight['VARIABLE'] == 'VAR_INFO_HEIGHT']\n",
    "        sites_table.loc[index, 'instrument_height'] = float(iheight_value['DATAVALUE'].values.tolist()[0])\n",
    "\n",
    "        cheight_file_path = os.path.join(data_directory,sites_folder,f\"ICOSETC_{id}_ANCILLARY_L2.csv\" )\n",
    "        cheight = pd.read_csv(cheight_file_path)\n",
    "        cheight = cheight[cheight['VARIABLE_GROUP'] == 'GRP_HEIGHTC']\n",
    "        cheight = cheight[cheight['VARIABLE'] == 'HEIGHTC']\n",
    "        cheight['DATAVALUE'] = cheight['DATAVALUE'].astype(float)\n",
    "        sites_table.loc[index, 'canopy_height'] = cheight.describe()['DATAVALUE'].loc['75%']\n",
    "        sites_table['buffer'] = 100 * (sites_table['instrument_height']-sites_table['canopy_height']*2/3) #Fetch to height ratio https://www.mdpi.com/2073-4433/10/6/299\n",
    "                                                                                                        #https://nicholas.duke.edu/people/faculty/katul/Matlab_footprint.html \n",
    "        sites_table['buffer_desired'] = sites_table['buffer'] / 3\n",
    "        sites_table['buffer_difference'] = sites_table['buffer_desired'] - sites_table['FETCH_90']\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {flux_file_path}\")\n",
    "        nan_files.append({flux_file_path}) \n",
    "        insitu = pd.DataFrame() \n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e}. The key 'FETCH' does not exist for station {id}.\")\n",
    "\n",
    "    return sites_table, nan_files, axs, insitu\n",
    "\n",
    "\n",
    "def plot_gpp(dobj, insitu, axs, output_directory):\n",
    "    nan_plots = []\n",
    "    try:\n",
    "        # Plot 3: Combined Plot\n",
    "        if 'GPP_DT_VUT_REF' in dobj.columns and 'GPP_DT_VUT_REF' in insitu.columns:\n",
    "            # Plot 3\n",
    "            dobj.plot(x='TIMESTAMP', y='GPP_DT_VUT_REF', grid=True, ax=axs[2], label='Dobj Data')\n",
    "            insitu.plot(x='TIMESTAMP', y='GPP_DT_VUT_REF', grid=True, ax=axs[2], label='Daily Data', linestyle='--')\n",
    "            axs[2].set_title(f'Combined GPP_DT_VUT_REF Over Time at {id} Station')\n",
    "            axs[2].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_directory, f'Combined_GPP_{id}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e}. The key 'GPP_DT_VUT_REF' does not exist in one of the dataframes for station {id}.\")\n",
    "        nan_plots.append(id)\n",
    "\n",
    "    return axs, nan_plots\n",
    "\n",
    "def elevation_icos_attributes(id, index, sites_table):\n",
    "    myStation = station.get(id)\n",
    "    metadata = myStation.info()\n",
    "    sites_table.loc[index, 'eas'] = metadata['eas'] \n",
    "    return sites_table\n",
    "\n",
    "def merge_data(data_directory, sites_folder, id, insitu_cols, directory_sentinel):\n",
    "    try:\n",
    "\n",
    "        sentinel = pd.read_csv(os.path.join(directory_sentinel,f\"{id}_Vegetation_indices_processed.csv\"), parse_dates=['date'])\n",
    "        sentinel.rename(columns={'date':'TIMESTAMP'}, inplace=True)\n",
    "        sentinel.set_index('TIMESTAMP', inplace=True)\n",
    "\n",
    "        flux_file_path = os.path.join(data_directory,sites_folder,f\"ICOSETC_{id}_FLUXNET_DD_L2.csv\" )\n",
    "        insitu = pd.read_csv(flux_file_path, index_col='TIMESTAMP', parse_dates=['TIMESTAMP'])\n",
    "        insitu = insitu[insitu_cols]\n",
    "\n",
    "        merged_input = pd.merge(left= insitu, right = sentinel, how=\"inner\", left_index = True , right_index = True)\n",
    "        merged_input['TIMESTAMP'] = pd.to_datetime(merged_input.index)\n",
    "        merged_input['lat'] = row['lat']\n",
    "        merged_input['lon'] = row['lon']\n",
    "        merged_input['elevation'] = row['eas']\n",
    "        merged_input['canopy_height'] = row['canopy_height']\n",
    "        merged_input['month'] = pd.DatetimeIndex(merged_input['TIMESTAMP']).month\n",
    "        merged_input['day'] = pd.DatetimeIndex(merged_input['TIMESTAMP']).day\n",
    "        # merged_input = merged_input[merged_input['TIMESTAMP'].dt.year >= row['years_keep']]\n",
    "        start, end = merged_input['TIMESTAMP'].iloc[[0, -1]]\n",
    "\n",
    "        merged_input.drop(columns=['TIMESTAMP'], inplace=True)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {flux_file_path}\")\n",
    "        merged_input = pd.DataFrame() \n",
    "    \n",
    "    return merged_input, start, end\n",
    "\n",
    "# FUNCTIONS\n",
    "def additional_gobal(df,data):\n",
    "    # Adding season data\n",
    "    month_to_season = {\n",
    "        1: 'winter', 2: 'winter', 3: 'spring',\n",
    "        4: 'spring', 5: 'spring', 6: 'summer',\n",
    "        7: 'summer', 8: 'summer', 9: 'fall',\n",
    "        10: 'fall', 11: 'fall', 12: 'winter'\n",
    "    }\n",
    "    data['season'] = data['month'].map(month_to_season)\n",
    "    df_encoded = pd.get_dummies(data, columns=['season'], prefix='season')\n",
    "    data[['winter', 'spring', 'summer', 'fall']] = df_encoded[['season_winter', 'season_spring', 'season_summer', 'season_fall']].astype(int)\n",
    "    data.drop(columns = ['season'], inplace = True)\n",
    "    \n",
    "    #Adding ecosystem type data\n",
    "    df = pd.get_dummies(df, columns=['ecosystemType'], prefix='biom')\n",
    "    df[['biom_evergreen needleleaf forests','biom_grasslands','biom_deciduous broadleaf forests','biom_mixed forests']]=df[['biom_evergreen needleleaf forests','biom_grasslands','biom_deciduous broadleaf forests','biom_mixed forests']].astype(int)\n",
    "    data['biom_evergreen needleleaf forests'] = df.loc[df['sites_ids'] == id, 'biom_evergreen needleleaf forests'].iloc[0]\n",
    "    data['biom_grasslands'] = df.loc[df['sites_ids'] == id, 'biom_grasslands'].iloc[0]\n",
    "    data['biom_deciduous broadleaf forests'] = df.loc[df['sites_ids'] == id, 'biom_deciduous broadleaf forests'].iloc[0]\n",
    "    data['biom_mixed forests'] = df.loc[df['sites_ids'] == id, 'biom_mixed forests'].iloc[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Site ID: FI-Sii\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Sii_ARCHIVE_L2\\ICOSETC_FI-Sii_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 346\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: IT-SR2\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_IT-SR2_ARCHIVE_L2\\ICOSETC_IT-SR2_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 346\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: SE-Htm\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_SE-Htm_ARCHIVE_L2\\ICOSETC_SE-Htm_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: GL-Dsk\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_GL-Dsk_ARCHIVE_L2\\ICOSETC_GL-Dsk_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 344\n",
      "Number of columns dropped: 14\n",
      "Columns dropped: ['LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: GF-Guy\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_GF-Guy_ARCHIVE_L2\\ICOSETC_GF-Guy_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 336\n",
      "Number of columns dropped: 59\n",
      "Columns dropped: ['G_F_MDS', 'LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_NT_VUT_REF', 'RECO_NT_VUT_USTAR50', 'RECO_NT_VUT_MEAN', 'RECO_NT_VUT_SE', 'RECO_NT_VUT_05', 'RECO_NT_VUT_16', 'RECO_NT_VUT_25', 'RECO_NT_VUT_50', 'RECO_NT_VUT_75', 'RECO_NT_VUT_84', 'RECO_NT_VUT_95', 'RECO_NT_CUT_REF', 'RECO_NT_CUT_USTAR50', 'RECO_NT_CUT_MEAN', 'RECO_NT_CUT_SE', 'RECO_NT_CUT_05', 'RECO_NT_CUT_16', 'RECO_NT_CUT_25', 'RECO_NT_CUT_50', 'RECO_NT_CUT_75', 'RECO_NT_CUT_84', 'RECO_NT_CUT_95', 'GPP_NT_VUT_REF', 'GPP_NT_VUT_USTAR50', 'GPP_NT_VUT_MEAN', 'GPP_NT_VUT_SE', 'GPP_NT_VUT_05', 'GPP_NT_VUT_16', 'GPP_NT_VUT_25', 'GPP_NT_VUT_50', 'GPP_NT_VUT_75', 'GPP_NT_VUT_84', 'GPP_NT_VUT_95', 'GPP_NT_CUT_REF', 'GPP_NT_CUT_USTAR50', 'GPP_NT_CUT_MEAN', 'GPP_NT_CUT_SE', 'GPP_NT_CUT_05', 'GPP_NT_CUT_16', 'GPP_NT_CUT_25', 'GPP_NT_CUT_50', 'GPP_NT_CUT_75', 'GPP_NT_CUT_84', 'GPP_NT_CUT_95', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FI-Kmp\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Kmp_ARCHIVE_L2\\ICOSETC_FI-Kmp_FLUXNET_DD_L2.csv\n",
      "File not found: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Kmp_ARCHIVE_L2\\ICOSETC_FI-Kmp_FLUXNET_DD_L2.csv\n",
      "\n",
      "Site ID: CD-Ygb\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_CD-Ygb_ARCHIVE_L2\\ICOSETC_CD-Ygb_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 340\n",
      "Number of columns dropped: 19\n",
      "Columns dropped: ['G_F_MDS', 'LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_NT_VUT_USTAR50', 'RECO_NT_CUT_USTAR50', 'GPP_NT_VUT_USTAR50', 'GPP_NT_CUT_USTAR50', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: IT-BFt\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_IT-BFt_ARCHIVE_L2\\ICOSETC_IT-BFt_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 326\n",
      "Number of columns dropped: 4\n",
      "Columns dropped: ['LW_IN_F_MDS', 'LW_IN_F_MDS_QC', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: IT-Tor\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_IT-Tor_ARCHIVE_L2\\ICOSETC_IT-Tor_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 334\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: GR-HeM\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_GR-HeM_ARCHIVE_L2\\ICOSETC_GR-HeM_FLUXNET_DD_L2.csv\n",
      "File not found: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_GR-HeM_ARCHIVE_L2\\ICOSETC_GR-HeM_FLUXNET_DD_L2.csv\n",
      "\n",
      "Site ID: GR-HeK\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_GR-HeK_ARCHIVE_L2\\ICOSETC_GR-HeK_FLUXNET_DD_L2.csv\n",
      "File not found: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_GR-HeK_ARCHIVE_L2\\ICOSETC_GR-HeK_FLUXNET_DD_L2.csv\n",
      "\n",
      "Site ID: FR-CLt\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-CLt_ARCHIVE_L2\\ICOSETC_FR-CLt_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 215\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-BeR\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-BeR_ARCHIVE_L2\\ICOSETC_DE-BeR_FLUXNET_DD_L2.csv\n",
      "File not found: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-BeR_ARCHIVE_L2\\ICOSETC_DE-BeR_FLUXNET_DD_L2.csv\n",
      "\n",
      "Site ID: IT-Noe\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_IT-Noe_ARCHIVE_L2\\ICOSETC_IT-Noe_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 219\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: IT-Niv\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_IT-Niv_ARCHIVE_L2\\ICOSETC_IT-Niv_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 322\n",
      "Number of columns dropped: 17\n",
      "Columns dropped: ['LW_IN_F_MDS', 'LW_IN_F_MDS_QC', 'G_F_MDS', 'LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: IT-Lsn\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_IT-Lsn_ARCHIVE_L2\\ICOSETC_IT-Lsn_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 334\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: GL-ZaH\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_GL-ZaH_ARCHIVE_L2\\ICOSETC_GL-ZaH_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 332\n",
      "Number of columns dropped: 14\n",
      "Columns dropped: ['LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: GL-NuF\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_GL-NuF_ARCHIVE_L2\\ICOSETC_GL-NuF_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 330\n",
      "Number of columns dropped: 14\n",
      "Columns dropped: ['LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Tou\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Tou_ARCHIVE_L2\\ICOSETC_FR-Tou_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 386\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Mej\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Mej_ARCHIVE_L2\\ICOSETC_FR-Mej_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 342\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-EM2\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-EM2_ARCHIVE_L2\\ICOSETC_FR-EM2_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 350\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Aur\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Aur_ARCHIVE_L2\\ICOSETC_FR-Aur_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FI-Var\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Var_ARCHIVE_L2\\ICOSETC_FI-Var_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 332\n",
      "Number of columns dropped: 4\n",
      "Columns dropped: ['LW_IN_F_MDS', 'LW_IN_F_MDS_QC', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FI-Tvm\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Tvm_ARCHIVE_L2\\ICOSETC_FI-Tvm_FLUXNET_DD_L2.csv\n",
      "File not found: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Tvm_ARCHIVE_L2\\ICOSETC_FI-Tvm_FLUXNET_DD_L2.csv\n",
      "\n",
      "Site ID: FI-Let\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Let_ARCHIVE_L2\\ICOSETC_FI-Let_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 332\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FI-Kvr\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Kvr_ARCHIVE_L2\\ICOSETC_FI-Kvr_FLUXNET_DD_L2.csv\n",
      "File not found: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Kvr_ARCHIVE_L2\\ICOSETC_FI-Kvr_FLUXNET_DD_L2.csv\n",
      "\n",
      "Site ID: FI-Ken\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Ken_ARCHIVE_L2\\ICOSETC_FI-Ken_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 328\n",
      "Number of columns dropped: 16\n",
      "Columns dropped: ['LW_IN_F_MDS', 'LW_IN_F_MDS_QC', 'LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: ES-LMa\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_ES-LMa_ARCHIVE_L2\\ICOSETC_ES-LMa_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 340\n",
      "Number of columns dropped: 15\n",
      "Columns dropped: ['G_F_MDS', 'LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-RuW\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-RuW_ARCHIVE_L2\\ICOSETC_DE-RuW_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 344\n",
      "Number of columns dropped: 14\n",
      "Columns dropped: ['LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-RuR\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-RuR_ARCHIVE_L2\\ICOSETC_DE-RuR_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 330\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-Msr\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-Msr_ARCHIVE_L2\\ICOSETC_DE-Msr_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 334\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-Kli\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-Kli_ARCHIVE_L2\\ICOSETC_DE-Kli_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 350\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-Hzd\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-Hzd_ARCHIVE_L2\\ICOSETC_DE-Hzd_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 229\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-Har\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-Har_ARCHIVE_L2\\ICOSETC_DE-Har_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 346\n",
      "Number of columns dropped: 15\n",
      "Columns dropped: ['G_F_MDS', 'LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-Gri\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-Gri_ARCHIVE_L2\\ICOSETC_DE-Gri_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 350\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: CZ-wet\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_CZ-wet_ARCHIVE_L2\\ICOSETC_CZ-wet_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 340\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-Hai\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-Hai_ARCHIVE_L2\\ICOSETC_DE-Hai_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 342\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Lqu\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Lqu_ARCHIVE_L2\\ICOSETC_FR-Lqu_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 231\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: BE-Dor\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_BE-Dor_ARCHIVE_L2\\ICOSETC_BE-Dor_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 229\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: CH-Dav\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_CH-Dav_ARCHIVE_L2\\ICOSETC_CH-Dav_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 356\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: UK-AMo\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_UK-AMo_ARCHIVE_L2\\ICOSETC_UK-AMo_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 344\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: SE-Svb\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_SE-Svb_ARCHIVE_L2\\ICOSETC_SE-Svb_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: SE-Sto\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_SE-Sto_ARCHIVE_L2\\ICOSETC_SE-Sto_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 233\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: SE-Nor\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_SE-Nor_ARCHIVE_L2\\ICOSETC_SE-Nor_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 342\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: SE-Deg\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_SE-Deg_ARCHIVE_L2\\ICOSETC_SE-Deg_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: NL-Loo\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_NL-Loo_ARCHIVE_L2\\ICOSETC_NL-Loo_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 227\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: IT-Ren\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_IT-Ren_ARCHIVE_L2\\ICOSETC_IT-Ren_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 346\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: IT-MBo\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_IT-MBo_ARCHIVE_L2\\ICOSETC_IT-MBo_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 229\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: IT-Cp2\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_IT-Cp2_ARCHIVE_L2\\ICOSETC_IT-Cp2_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: IT-BCi\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_IT-BCi_ARCHIVE_L2\\ICOSETC_IT-BCi_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 245\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: GL-ZaF\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_GL-ZaF_ARCHIVE_L2\\ICOSETC_GL-ZaF_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 221\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Pue\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Pue_ARCHIVE_L2\\ICOSETC_FR-Pue_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Lus\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Lus_ARCHIVE_L2\\ICOSETC_FR-Lus_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 231\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Lam\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Lam_ARCHIVE_L2\\ICOSETC_FR-Lam_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 350\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Hes\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Hes_ARCHIVE_L2\\ICOSETC_FR-Hes_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 233\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Gri\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Gri_ARCHIVE_L2\\ICOSETC_FR-Gri_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Fon\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Fon_ARCHIVE_L2\\ICOSETC_FR-Fon_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 370\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-FBn\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-FBn_ARCHIVE_L2\\ICOSETC_FR-FBn_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 229\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-Bil\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-Bil_ARCHIVE_L2\\ICOSETC_FR-Bil_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 354\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FI-Sod\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Sod_ARCHIVE_L2\\ICOSETC_FI-Sod_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 231\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FI-Hyy\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FI-Hyy_ARCHIVE_L2\\ICOSETC_FI-Hyy_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DK-Vng\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DK-Vng_ARCHIVE_L2\\ICOSETC_DK-Vng_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 350\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DK-Sor\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DK-Sor_ARCHIVE_L2\\ICOSETC_DK-Sor_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-Tha\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-Tha_ARCHIVE_L2\\ICOSETC_DE-Tha_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 344\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-RuS\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-RuS_ARCHIVE_L2\\ICOSETC_DE-RuS_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-HoH\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-HoH_ARCHIVE_L2\\ICOSETC_DE-HoH_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 354\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DE-Geb\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DE-Geb_ARCHIVE_L2\\ICOSETC_DE-Geb_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 352\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: CZ-Lnz\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_CZ-Lnz_ARCHIVE_L2\\ICOSETC_CZ-Lnz_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 231\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: CZ-BK1\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_CZ-BK1_ARCHIVE_L2\\ICOSETC_CZ-BK1_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 229\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: BE-Vie\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_BE-Vie_ARCHIVE_L2\\ICOSETC_BE-Vie_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: BE-Maa\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_BE-Maa_ARCHIVE_L2\\ICOSETC_BE-Maa_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: BE-Lon\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_BE-Lon_ARCHIVE_L2\\ICOSETC_BE-Lon_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 346\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: BE-Bra\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_BE-Bra_ARCHIVE_L2\\ICOSETC_BE-Bra_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 348\n",
      "Number of columns dropped: 2\n",
      "Columns dropped: ['RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: FR-LGt\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_FR-LGt_ARCHIVE_L2\\ICOSETC_FR-LGt_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 336\n",
      "Number of columns dropped: 15\n",
      "Columns dropped: ['G_F_MDS_QC', 'LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DK-Skj\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DK-Skj_ARCHIVE_L2\\ICOSETC_DK-Skj_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 334\n",
      "Number of columns dropped: 18\n",
      "Columns dropped: ['LW_IN_F_MDS', 'LW_IN_F_MDS_QC', 'G_F_MDS', 'G_F_MDS_QC', 'LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: DK-Gds\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_DK-Gds_ARCHIVE_L2\\ICOSETC_DK-Gds_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 334\n",
      "Number of columns dropped: 18\n",
      "Columns dropped: ['LW_IN_F_MDS', 'LW_IN_F_MDS_QC', 'G_F_MDS', 'G_F_MDS_QC', 'LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "\n",
      "Site ID: BE-Lcr\n",
      "\n",
      "Reading: D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC\\ICOSETC_BE-Lcr_ARCHIVE_L2\\ICOSETC_BE-Lcr_FLUXNET_DD_L2.csv\n",
      "Original number of columns: 346\n",
      "Number of columns dropped: 15\n",
      "Columns dropped: ['G_F_MDS_QC', 'LE_F_MDS_QC', 'LE_CORR', 'LE_CORR_25', 'LE_CORR_75', 'LE_CORR_JOINTUNC', 'H_F_MDS_QC', 'H_CORR', 'H_CORR_25', 'H_CORR_75', 'H_CORR_JOINTUNC', 'EBC_CF_N', 'EBC_CF_METHOD', 'RECO_SR', 'RECO_SR_N']\n",
      "\n",
      "Number of columns available in all files: 159\n",
      "Number of columns available in all files without carbon data: 44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_directory = r'D:\\Proyectos2024\\Agame\\Input\\Flux_data\\ICOSETC'\n",
    "directory_sentinel = r'D:\\Proyectos2024\\Agame\\Output\\sentinel2\\VI_output'\n",
    "directory_site_selection = r'D:\\Proyectos2024\\Agame\\Output\\sites_selection'\n",
    "output_directory = r'D:\\Proyectos2024\\Agame\\Output\\Tables'\n",
    "\n",
    "sites_table = pd.read_csv(os.path.join(data_directory,'!TOC.csv'))\n",
    "sites_table['sites_ids'] = sites_table['File name'].apply(lambda x: x.split('_')[1])\n",
    "sites_table['sites_folder'] = sites_table['File name'].apply(lambda x: x.replace('.zip', ''))\n",
    "insitu_cols = filter_flux_columns(data_directory, sites_table)\n",
    "\n",
    "sites_table = pd.read_csv(os.path.join(directory_site_selection,'sites_table_filtered_4y.csv'), sep=';')\n",
    "#sites_table = sites_table[sites_table['sites_ids'] == 'IT-Tor']\n",
    "#sites_table_s = sites_table[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process for:  0 IT-SR2\n",
      "Process for:  1 SE-Htm\n",
      "Process for:  2 IT-Tor\n",
      "Process for:  3 IT-Niv\n",
      "Process for:  4 FR-Mej\n",
      "Process for:  5 DE-Msr\n",
      "Process for:  6 DE-Har\n",
      "Process for:  7 DE-Hai\n",
      "Process for:  8 CH-Dav\n",
      "Process for:  9 SE-Svb\n",
      "Process for:  10 SE-Nor\n",
      "Process for:  11 FR-Fon\n",
      "Process for:  12 FR-Bil\n",
      "Process for:  13 FI-Hyy\n",
      "Process for:  14 DE-Tha\n",
      "Process for:  15 DE-HoH\n",
      "Process for:  16 BE-Vie\n",
      "Process for:  17 BE-Bra\n"
     ]
    }
   ],
   "source": [
    "for index, row in sites_table.iterrows():\n",
    "    id = row['sites_ids']\n",
    "    sites_folder = row['sites_folder']\n",
    "    print('Process for: ',index, id)\n",
    "    merged_input, start, end = merge_data(data_directory, sites_folder, id, insitu_cols, directory_sentinel)\n",
    "    merged_input = additional_gobal(sites_table, merged_input)\n",
    "\n",
    "    # merged_input  = merged_input[merged_input['NEE_VUT_REF_QC']>0.5]\n",
    "    merged_input  = merged_input.drop('NEE_VUT_REF_QC', axis=1) \n",
    "    merged_input.to_csv(os.path.join(output_directory,f\"{id}_preprocessed_{start.strftime('%d%m%Y')}_{end.strftime('%d%m%Y')}.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deltares_GPP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
